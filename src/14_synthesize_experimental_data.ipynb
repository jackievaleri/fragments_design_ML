{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2122cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "# shut off warnings\n",
    "from rdkit import RDLogger                                                                                                                                                               \n",
    "RDLogger.DisableLog('rdApp.*')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9824e880",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23f9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_hits_from_df(df, thresh):\n",
    "    confirmvals = []\n",
    "    for _, odvals in df.items():\n",
    "        confirmed_hit = False\n",
    "        for x in list(odvals):\n",
    "            if x < thresh:\n",
    "                confirmed_hit = True\n",
    "        confirmvals.append(confirmed_hit)\n",
    "    return(confirmvals)\n",
    "\n",
    "def call_hits_from_concentration_df(rep1, rep2, thresh):\n",
    "    # call a hit if highest concentration causes low OD\n",
    "    rep1_od = []\n",
    "    rep2_od = []\n",
    "    confirmvals = []\n",
    "    for i in range(len(rep1.iloc[0,:])):\n",
    "        confirmed_hit = False\n",
    "        highestconc_od1 = rep1.iloc[0,i]\n",
    "        highestconc_od2 = rep2.iloc[0,i]\n",
    "        rep1_od.append(highestconc_od1)\n",
    "        rep2_od.append(highestconc_od2)\n",
    "        if highestconc_od1 < thresh and highestconc_od2 < thresh:\n",
    "            confirmed_hit = True\n",
    "        confirmvals.append(confirmed_hit)\n",
    "    return(confirmvals, rep1_od, rep2_od)\n",
    "\n",
    "def match_mols_with_frags(moldf, moldf_smi_col, fragdf, fragdf_smi_col):\n",
    "    molsmis = list(moldf[moldf_smi_col])\n",
    "    mols = [Chem.MolFromSmiles(smi) for smi in molsmis]\n",
    "    fragsmis = list(fragdf[fragdf_smi_col])\n",
    "    frags = [Chem.MolFromSmiles(smi) for smi in fragsmis]\n",
    "\n",
    "    matched_frag_smis = []\n",
    "    matched_mol_smis = []\n",
    "    # find the fragments they match to\n",
    "    for i, mol in enumerate(mols):\n",
    "        for j, frag in enumerate(frags):\n",
    "            if mol.HasSubstructMatch(frag):\n",
    "                matched_frag_smis.append(fragsmis[j]) # only works bc all smiles make valid mols\n",
    "                matched_mol_smis.append(molsmis[i]) \n",
    "        \n",
    "    matchdf = pd.DataFrame()\n",
    "    matchdf['fragment_SMILES'] = matched_frag_smis\n",
    "    matchdf['SMILES'] = matched_mol_smis\n",
    "    return(matchdf)\n",
    "\n",
    "def report_stats(df, smi_col = 'SMILES', hit_col = 'Confirmed-Hit'):\n",
    "    # smi_col is mol smi col\n",
    "    dedup = df.drop_duplicates(smi_col)\n",
    "    length = len(dedup)\n",
    "    hits = sum([1.0 if x == True else 0.0 for x in list(dedup[hit_col])])\n",
    "    print('Number of compounds tested: ' + str(length))\n",
    "    print('Number of confirmed hits: ' + str(int(hits)))\n",
    "    print('Hit rate: ' + str(100 * np.round(float(hits)/length,4)) + '%')\n",
    "\n",
    "def match_molport_mols_with_diff_smis(smilist1, smilist2):\n",
    "    # find the fragments they match to\n",
    "    corr_smilist1 = [] # expect these are molport smis\n",
    "    corr_smilist2 = [] # expect these are our smis\n",
    "    for i, smi1 in enumerate(smilist1):\n",
    "        for j, smi2 in enumerate(smilist2):\n",
    "            if type(smi2) == float:\n",
    "                continue\n",
    "            mol1 = Chem.MolFromSmiles(smi1)\n",
    "            mol2 = Chem.MolFromSmiles(smi2)\n",
    "            if mol2 is None:\n",
    "                continue\n",
    "            if smi2 in ['FC(F)(F)c1cccc(c1)C(=O)c1c[nH]c(c1)C(=O)NC[C@H]1CCCO1', 'CC1=NOC(=C1NC(=O)NC1=CC=C(Cl)C=C1)C1=CC=C(C=C1)C(F)(F)F', 'OC(=O)C[C@H]1CC[C@@H](CC1)C1=CC=C(NC(=O)C2=NN=C(NC3=CC(F)=C(F)C=C3)O2)C=C1']:\n",
    "                continue # these are compounds w 2 matching compounds from our metadata list so we looked at the stereochemistry and picked the most similar\n",
    "                        \n",
    "            tan = DataStructs.TanimotoSimilarity(Chem.RDKFingerprint(mol1), Chem.RDKFingerprint(mol2))\n",
    "            if tan >= 1.0:\n",
    "                corr_smilist1.append(smi1)\n",
    "                corr_smilist2.append(smi2)\n",
    "    return(corr_smilist1, corr_smilist2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951a056",
   "metadata": {},
   "source": [
    "# SA-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd3b7e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 Statistics\n",
      "Number of compounds tested: 42\n",
      "Number of confirmed hits: 19\n",
      "Hit rate: 45.24%\n"
     ]
    }
   ],
   "source": [
    "# from the first experiment - all hits surveyed\n",
    "rd1_first_exps = pd.read_excel('../data/experimental_validation/sa_rd1.xlsx') # aarti did not save MIC data for these\n",
    "rd1_first_exps = rd1_first_exps[['Broad ID', 'SMILES', 'Name', 'Rep1', 'Rep2']]\n",
    "rd1_first_exps = rd1_first_exps.iloc[0:42,:]\n",
    "rd1_first_exps.columns = ['Broad_ID', 'SMILES', 'Name', 'Rep1-OD', 'Rep2-OD']\n",
    "rd1_first_exps['Hit-OD'] = [x < 0.3 and y < 0.3 for x,y in zip(rd1_first_exps['Rep1-OD'], rd1_first_exps['Rep2-OD'])]\n",
    "\n",
    "# hardcode the extraction of the CONFIRMED or NOT ODs with second round of validation\n",
    "rd1 = pd.read_excel('../data/experimental_validation/sa_rd1_addtnl.xlsx')\n",
    "cpd_smiles = list(rd1.iloc[4,2:26]) # first get names / labels\n",
    "sa_rep = rd1.iloc[6:14,2:26].reset_index(drop = True) # get OD values\n",
    "    \n",
    "# call a hit if any concentration causes OD < 0.3, using this second round validaton\n",
    "confirmdf = pd.DataFrame()\n",
    "confirmdf['SMILES'] = cpd_smiles\n",
    "confirmdf['Confirmed-Hit'] = call_hits_from_df(sa_rep, thresh = 0.3)\n",
    "rd1_first_exps = rd1_first_exps.merge(confirmdf, on = 'SMILES', how = 'left')\n",
    "\n",
    "# finally add in the fragment that we used\n",
    "predfrags = pd.read_csv('../out/fragment_algorithm_pipeline_runs/06_SA_rd1/candidates_after_matching_and_filtering.csv')\n",
    "matchdf = match_mols_with_frags(rd1_first_exps, 'SMILES', predfrags, 'fragment_SMILES')\n",
    "rd1_first_exps = rd1_first_exps.merge(matchdf, on = 'SMILES', how = 'left')\n",
    "\n",
    "# now add data to a running dataframe\n",
    "rd1_first_exps['Round'] = ['Round1-Pilot'] * len(rd1_first_exps)\n",
    "rd1_first_exps['ID'] = rd1_first_exps['Broad_ID']\n",
    "columns = ['Round', 'ID', 'Name', 'SMILES', 'fragment_SMILES','Rep1-OD', 'Rep2-OD', 'Hit-OD', 'Confirmed-Hit']\n",
    "rd1_first_exps = rd1_first_exps[columns]\n",
    "fulldf = pd.DataFrame(rd1_first_exps)\n",
    "\n",
    "print('Round 1 Statistics')\n",
    "report_stats(rd1_first_exps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b688ab",
   "metadata": {},
   "source": [
    "# SA-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512e83d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2 Statistics\n",
      "Number of compounds tested: 16\n",
      "Number of confirmed hits: 8\n",
      "Hit rate: 50.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/8hwb28r933z4xh4q0dw5hz2h0000gn/T/ipykernel_97472/2661858994.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  fulldf = fulldf.append(molport_order_manual)\n"
     ]
    }
   ],
   "source": [
    "# annoying our smiles don't match the smiles from molport, so have to merge the data\n",
    "molport_order_manual = pd.read_excel('../data/experimental_validation/sa_rd2.xlsx')\n",
    "molport_order_manual = molport_order_manual.iloc[0:16,:]\n",
    "metadata = pd.read_excel('../../generativeML/out/pipeline_v5_script/frag_0.05_17atom_800K_and_5mil/final_proposed_molecules_to_order_ANNOTATED_09_29_2022.xlsx')\n",
    "molportsmis = list(molport_order_manual['SMILES'])\n",
    "oursmis = list(metadata['SMILES'])\n",
    "match_molportsmis, match_oursmis = match_molport_mols_with_diff_smis(molportsmis, oursmis)\n",
    "metadata = metadata[[x in match_oursmis for x in oursmis]]\n",
    "\n",
    "# hardcode the extraction of the ODs and HEP/HEK growth from the second round concentration data\n",
    "rd2 = pd.read_excel('../data/experimental_validation/sa_rd2_addtnl.xlsx')\n",
    "cpd_smiles = list(rd2.iloc[2,2:10]) # first get names / labels\n",
    "cpd_names = list(rd2.iloc[3,2:10])\n",
    "sa_rep1 = rd2.iloc[5:13,2:10].reset_index(drop = True) # get OD values\n",
    "sa_rep2 = rd2.iloc[5:13,12:20].reset_index(drop = True)\n",
    "\n",
    "# call a hit if any concentration causes OD < 0.3, using this second round validaton\n",
    "confirmdf = pd.DataFrame()\n",
    "confirm_hits, rep1_od, rep2_od = call_hits_from_concentration_df(sa_rep1, sa_rep2, thresh = 0.3)\n",
    "confirmdf['Name'] = cpd_names\n",
    "confirmdf['Rep1-OD'] = rep1_od\n",
    "confirmdf['Rep2-OD'] = rep2_od\n",
    "confirmdf['Confirmed-Hit'] = confirm_hits\n",
    "molport_order_manual = molport_order_manual.merge(confirmdf, on = 'Name', how = 'left')\n",
    "molport_order_manual['Hit-OD'] = [bool(x) for x in list(molport_order_manual['OD-Hit'])]\n",
    "\n",
    "# finally add in the fragment that we used\n",
    "predfrags = pd.read_csv('../../generativeML/out/pipeline_v5_script/frag_0.05_17atom_800K_and_5mil/more_info_candidates_v1_08_16_2022.csv')\n",
    "matchdf = match_mols_with_frags(molport_order_manual, 'SMILES', predfrags, 'fragment_SMILES')\n",
    "molport_order_manual = molport_order_manual.merge(matchdf, on = 'SMILES', how = 'left')\n",
    "\n",
    "# now add data to a running dataframe\n",
    "molport_order_manual['Round'] = ['Round2-17atom'] * len(molport_order_manual)\n",
    "molport_order_manual['ID'] = molport_order_manual['Molport_ID']\n",
    "molport_order_manual = molport_order_manual[columns]\n",
    "fulldf = fulldf.append(molport_order_manual)\n",
    "\n",
    "print('Round 2 Statistics')\n",
    "report_stats(molport_order_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd47c317",
   "metadata": {},
   "source": [
    "# SA-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be9c39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 3 Statistics\n",
      "Number of compounds tested: 51\n",
      "Number of confirmed hits: 4\n",
      "Hit rate: 7.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/8hwb28r933z4xh4q0dw5hz2h0000gn/T/ipykernel_97472/4251235352.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  fulldf = fulldf.append(rd3)\n"
     ]
    }
   ],
   "source": [
    "# we do not have OD data on this - only have MIC on the hits from here\n",
    "rd3 = pd.read_csv('../../generativeML/out/pipeline_v5_script/frag_0.05_enamine18mil_mol_0.15_800K/final_proposed_and_annotated_mols_to_order_10_21_2022.csv')\n",
    "rd3['ID'] = rd3['Name']\n",
    "\n",
    "# positive hits reported by aarti\n",
    "confirmedhits = ['BRD-A29973139', 'BRD-A19217117', 'BRD-A80110716', 'BRD-K32533226']\n",
    "rd3['Confirmed-Hit'] = [x in confirmedhits for x in list(rd3['Name'])]\n",
    "\n",
    "# combine with fragments data\n",
    "predfrags = pd.read_csv('../../generativeML/out/pipeline_v5_script/frag_0.05_enamine18mil_mol_0.15_800K/more_info_candidates_v1_10_13_2022.csv')\n",
    "matchdf = match_mols_with_frags(rd3, 'SMILES', predfrags, 'fragment_SMILES')\n",
    "rd3 = rd3.merge(matchdf, on = 'SMILES', how = 'left')\n",
    "\n",
    "# now add data to a running dataframe\n",
    "rd3['Round'] = ['Round3-Enamine'] * len(rd3)\n",
    "pared_down_cols = [col for col in columns if col not in ['Rep1-OD', 'Rep2-OD', 'Hit-OD']]\n",
    "rd3 = rd3[pared_down_cols]\n",
    "fulldf = fulldf.append(rd3)\n",
    "\n",
    "print('Round 3 Statistics')\n",
    "report_stats(rd3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e22cdba",
   "metadata": {},
   "source": [
    "# SA-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a9d41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 4 Statistics\n",
      "Number of compounds tested: 14\n",
      "Number of confirmed hits: 4\n",
      "Hit rate: 28.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/8hwb28r933z4xh4q0dw5hz2h0000gn/T/ipykernel_97472/3603594006.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  fulldf = fulldf.append(round4)\n"
     ]
    }
   ],
   "source": [
    "# get combined data for round 4 and round 5\n",
    "rd45 = pd.read_excel('../data/experimental_validation/sa_rd4_rd5_addtnl.xlsx')\n",
    "labels = ['Round4-Enamine Fragments+Broad'] * 14\n",
    "labels.extend(['Round5-GDB11,17+Broad'] * 17)\n",
    "rd45['Round'] = labels\n",
    "rd45['Rep1-OD'] = rd45['SA at 100uM']\n",
    "rd45['ID'] = rd45['Name']\n",
    "rd45 = rd45[['Round', 'ID', 'Name', 'SMILES', 'Rep1-OD']]\n",
    "rd45['Hit-OD'] = [x < 0.3 for x in list(rd45['Rep1-OD'])]\n",
    "\n",
    "# combine with fragments data - round 4\n",
    "round4 = rd45[rd45['Round'] == 'Round4-Enamine Fragments+Broad']\n",
    "rd4preds = pd.read_csv('../../generativeML/out/pipeline_v6_script/frag_0.05_allfrags_mol_0.15_800K/more_info_candidates_v1_12_16_2022.csv')\n",
    "matchdf = match_mols_with_frags(round4, 'SMILES', rd4preds, 'fragment_SMILES')\n",
    "round4 = round4.merge(matchdf, on = 'SMILES', how = 'left')\n",
    "\n",
    "# add to running df\n",
    "fulldf = fulldf.append(round4)\n",
    "print('Round 4 Statistics')\n",
    "report_stats(round4, hit_col = 'Hit-OD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c1f48c",
   "metadata": {},
   "source": [
    "# SA-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5543a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 5 Statistics\n",
      "Number of compounds tested: 17\n",
      "Number of confirmed hits: 6\n",
      "Hit rate: 35.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/8hwb28r933z4xh4q0dw5hz2h0000gn/T/ipykernel_97472/2524553870.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  fulldf = fulldf.append(round5)\n"
     ]
    }
   ],
   "source": [
    "round5 = rd45[rd45['Round'] == 'Round5-GDB11,17+Broad']\n",
    "# combine with fragments data - round 5\n",
    "rd5preds = pd.read_csv('../../generativeML/out/pipeline_v6_script/frag_0.05_allfrags_mol_0.15_800K_redo_with_gdb11_and_17_fix_mistake/more_info_candidates_v1_12_20_2022.csv')\n",
    "matchdf = match_mols_with_frags(round5, 'SMILES', rd5preds, 'fragment_SMILES')\n",
    "round5 = round5.merge(matchdf, on = 'SMILES', how = 'left')\n",
    "\n",
    "# add to running df\n",
    "fulldf = fulldf.append(round5)\n",
    "print('Round 5 Statistics')\n",
    "report_stats(round5, hit_col = 'Hit-OD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba9245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf.to_csv('../data/experimental_validation/combined_cpd_and_frag_results_up_through_round5_sa.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436468a6",
   "metadata": {},
   "source": [
    "# SA-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3be01ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 6 Statistics\n",
      "Number of compounds tested: 31\n",
      "Number of confirmed hits: 5\n",
      "Hit rate: 16.13%\n"
     ]
    }
   ],
   "source": [
    "# combine with fragments data - round 6\n",
    "rd6 = pd.read_excel('../data/experimental_validation/sa_rd6.xlsx', header = 1)\n",
    "rd6.columns = ['', 'Compound', 'Rep1-OD', 'Rep1-MRSA', 'Rep2-OD', 'Rep1-MRSA', 'ID', 'Formula', 'MW', 'SMILES']\n",
    "rd6['Round'] = ['Round6-Enamine_frags_no_cpd'] * len(rd6)\n",
    "rd6['Name'] = ['mol' + str(i) for i in list(rd6['Compound'])]\n",
    "rd6['Confirmed-Hit'] = [1.0 if x < 0.2 and y < 0.2 else 0.0 for x,y in zip(rd6['Rep1-OD'], rd6['Rep2-OD'])]\n",
    "\n",
    "# combine with fragments data - round 6\n",
    "rd6preds = pd.read_csv('../../generativeML/out/pipeline_v5_script/enamine_fragments_alone_v1/fragment_clusters_over_0.3/finalmols.csv')\n",
    "matchdf = match_mols_with_frags(rd6, 'SMILES', rd6preds, 'fragment_SMILES')\n",
    "rd6 = rd6.merge(matchdf, on = 'SMILES', how = 'left')\n",
    "rd6 = rd6[['Round', 'ID', 'Name', 'SMILES', 'fragment_SMILES', 'Rep1-OD', 'Rep2-OD', 'Confirmed-Hit']]\n",
    "\n",
    "# save it to its own dataframe\n",
    "rd6.to_csv('../data/experimental_validation/round6_cleaned_results.csv', index=False)\n",
    "\n",
    "print('Round 6 Statistics')\n",
    "report_stats(rd6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a326dd",
   "metadata": {},
   "source": [
    "# Get just active SA fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "770c5cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# through round 5\n",
    "df = pd.read_csv('../data/experimental_validation/combined_cpd_and_frag_results_up_through_round5_sa.csv')\n",
    "\n",
    "# keep if only have one \"Hit-OD\" or \"Confirmed-Hit\" and that one is positive; if we have both data, only keep if Confirmed-Hit = True\n",
    "keep_indices = []\n",
    "index = 0\n",
    "for hit, confirmed in zip(list(df['Hit-OD']), list(df['Confirmed-Hit'])):\n",
    "    if hit is True and type(confirmed) is float:\n",
    "        keep_indices.append(index)\n",
    "    elif type(hit) is float and confirmed is True:\n",
    "        keep_indices.append(index)\n",
    "    elif hit is True and confirmed is True:\n",
    "        keep_indices.append(index)\n",
    "    index = index + 1\n",
    "\n",
    "df = df.iloc[keep_indices]\n",
    "df = df.reset_index(drop = True)\n",
    "df['compound_SMILES'] = list(df['SMILES'])\n",
    "df = df[['Round','ID','Name','compound_SMILES','fragment_SMILES']]\n",
    "df['Compound_of_Interest'] = ['Y' if n == '8M-713' else 'N' for n in list(df['Name'])]\n",
    "df.to_csv('../data/experimental_validation/successful_combined_cpd_and_frag_results_up_through_round5_sa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21fdc4",
   "metadata": {},
   "source": [
    "# NG-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e42fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NG Round 1 Statistics\n",
      "Number of compounds tested: 70\n",
      "Number of confirmed hits: 7\n",
      "Hit rate: 10.0%\n"
     ]
    }
   ],
   "source": [
    "# get metadata for round 1 ng\n",
    "rd1_first_exps = pd.read_excel('../data/experimental_validation/ng_rd1.xlsx', header = 1) # aarti did not save MIC data for these\n",
    "\n",
    "# asked melis to do a third/fourth rep of BRD-K54582152 because of two reps being wonky\n",
    "cpd_names = []\n",
    "binary_hits = []\n",
    "for cpd, smalldf in rd1_first_exps.groupby('Broad Sample ID'):\n",
    "    dftopconc = smalldf.dropna(subset = 'Graver Wade\\n_1')\n",
    "    dftopconc = dftopconc.sort_values('umol/L final', ascending = False)\n",
    "    dftopconc = dftopconc.iloc[0,:]\n",
    "    try: \n",
    "        float(dftopconc['Graver Wade\\n_1'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        display(smalldf)\n",
    "    avg_GW = np.mean([dftopconc['Graver Wade\\n_1'], dftopconc['Graver Wade\\n_2']])\n",
    "    cpd_names.append(cpd)\n",
    "    binary_hits.append(1.0 if avg_GW < 60 else 0.0)\n",
    "\n",
    "# get the SMILES metadata\n",
    "df = pd.DataFrame()\n",
    "df['Broad_ID'] = cpd_names\n",
    "df['hit'] = binary_hits\n",
    "meta = pd.read_csv('../out/fragment_algorithm_pipeline_runs/12_NG_rd1/candidate_compounds_after_matching_and_filtering_with_metadata.csv')\n",
    "meta = meta[['Name', 'smiles']]\n",
    "meta.columns = ['Name', 'SMILES']\n",
    "df['Name'] = [x.split('-')[0] + '-' + x.split('-')[1] for x in list(df['Broad_ID'])]\n",
    "df = df.merge(meta, on = 'Name', how = 'left')\n",
    "\n",
    "# finally add in the fragment that we used\n",
    "predfrags = pd.read_csv('../out/fragment_algorithm_pipeline_runs/12_NG_rd1/candidates_after_matching_and_filtering.csv')\n",
    "matchdf = match_mols_with_frags(df, 'SMILES', rd6preds, 'fragment_SMILES')\n",
    "df = df.merge(matchdf, on = 'SMILES', how = 'left')\n",
    "\n",
    "# add metadata and save\n",
    "df['Round'] = ['Round1-NG'] * len(df)\n",
    "df['ID'] = df['Broad_ID']\n",
    "df = df[['Round', 'Name', 'hit', 'SMILES', 'fragment_SMILES']]\n",
    "df.to_csv('../data/experimental_validation/ng_rd1_experimental.csv', index = False)\n",
    "\n",
    "print('NG Round 1 Statistics')\n",
    "report_stats(df, hit_col = 'hit')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
