{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69eb029b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackie16201/Desktop/Spring_2023/fragments_discovery_design_ML/src/pipeline.py:12: DeprecationWarning: The rdkit.Chem.MCS module is deprecated; please use rdkit.Chem.rdFMCS instead.\n",
      "  from rdkit.Chem import MCS\n",
      "/Users/jackie16201/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "/Users/jackie16201/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pipeline import mini_algo, threshold_on_score, keep_valid_molecules, check_pains_brenk\n",
    "from utils import evaluate_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e529887f",
   "metadata": {},
   "source": [
    "# Part 1: Get neural network baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff32e66a",
   "metadata": {},
   "source": [
    "First, we trained an underpowered model on the 2.3K compound staph screen. We use this model to predict on the 37K staph screen and the 27mil fragments. Training code can be found in 05_in_silico_algorithm_control.sh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d15c583e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359 experimental hits out of 1518.0 predicted hits\n",
      "precision recall: 0.08686796118642708\n",
      "recall: \n",
      "0.13370473537604458\n",
      "precision: \n",
      "0.03162055335968379\n"
     ]
    }
   ],
   "source": [
    "cpd_df = pd.read_csv('../out/controls/in_silico_algorithm_control_SA_37k_predictions_with_2300_model.csv')\n",
    "all_cpd_df = cpd_df.copy()\n",
    "\n",
    "# use the algo-predicted cpds as \"positive\" and the rest of cpds as negative - FOR ALL CPDS\n",
    "all_cpd_df['predicted_with_gnn'] = [1.0 if x > 0.2 else 0.0 for x in list(all_cpd_df['class'])]\n",
    "all_cpd_df['experimental_hit'] = list(all_cpd_df['Mean_50uM'] < 0.2)\n",
    "print(str(sum(all_cpd_df['experimental_hit'])) + ' experimental hits out of ' + str(sum(all_cpd_df['predicted_with_gnn'])) + ' predicted hits')\n",
    "evaluate_model(all_cpd_df, cutoff_for_positive = 0.2, actual_col='experimental_hit', predicted_col='predicted_with_gnn')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "469d64c7",
   "metadata": {},
   "source": [
    "# Part 2: Get neural network baseline plus checking for PAINS and Brenk like fragment algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e046bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of cpd preds:  36977\n",
      "length of df >0.2:  1518\n",
      "length of df with valid mols:  1518\n",
      "length of all preds with clean (no PAINS or Brenk) mols:  1351\n",
      "359 experimental hits out of 1351.0 predicted hits\n",
      "precision recall: 0.039841008255136576\n",
      "recall: \n",
      "0.055710306406685235\n",
      "precision: \n",
      "0.014803849000740192\n"
     ]
    }
   ],
   "source": [
    "print('length of cpd preds: ', len(cpd_df))\n",
    "# threshold on score\n",
    "cpd_df = threshold_on_score(cpd_df, 0.2, 'class')\n",
    "# keep only valid molecules\n",
    "cpd_df, cpd_mols = keep_valid_molecules(cpd_df, 'SMILES')\n",
    "# keep only molecules without pains or brenk\n",
    "cpd_df, cpd_mols = check_pains_brenk(cpd_df, cpd_mols)\n",
    "\n",
    "predicted_positive_cpds = list(cpd_df['Compound_ID'])\n",
    "all_cpd_df['predicted_with_gnn_plus_processing'] = [1.0 if x in predicted_positive_cpds else 0.0 for x in list(all_cpd_df['Compound_ID'])]\n",
    "print(str(sum(all_cpd_df['experimental_hit'])) + ' experimental hits out of ' + str(sum(all_cpd_df['predicted_with_gnn_plus_processing'])) + ' predicted hits')\n",
    "evaluate_model(all_cpd_df, cutoff_for_positive = 0.2, actual_col='experimental_hit', predicted_col='predicted_with_gnn_plus_processing')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ad7b9b8",
   "metadata": {},
   "source": [
    "# Part 3: Actual fragment algorithm test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c24a199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing fragments...\n",
      "length of df:  25020000\n",
      "length of df >0.1:  3307974\n",
      "length of df with more than C,O,H characters:  3202807\n",
      "length of df with valid mols:  3202807\n"
     ]
    }
   ],
   "source": [
    "# Values for processing fragments and compounds\n",
    "fragment_path = '../out/controls/in_silico_algorithm_control_SA_all_combined_fragment_preds_gdb11_with_2300.csv'\n",
    "compound_path = '../out/controls/in_silico_algorithm_control_SA_37k_predictions_with_2300_model.csv'\n",
    "result_path = '../out/controls/in_silico_algorithm_control_SA_'\n",
    "fragment_smi_col = 'SMILES'\n",
    "compound_smi_col = 'SMILES'\n",
    "fragment_hit_col = 'class'\n",
    "compound_hit_col = 'class'\n",
    "\n",
    "# filters and thresholds for fragments and compounds\n",
    "fragment_score = 0.1\n",
    "compound_score = 0.2\n",
    "fragment_remove_pains_brenk = 'both' # one of 'both', 'pains', 'brenk', 'none'\n",
    "compound_remove_pains_brenk = 'both' # one of 'both', 'pains', 'brenk', 'none'\n",
    "fragment_require_more_than_coh = True\n",
    "frags_cannot_disrupt_rings = True\n",
    "\n",
    "rank_df, cpd_df = mini_algo(fragment_path=fragment_path,\n",
    "                    compound_path=compound_path,\n",
    "                    result_path=result_path,\n",
    "                    fragment_smi_col=fragment_smi_col,\n",
    "                    compound_smi_col=compound_smi_col,\n",
    "                    fragment_hit_col=fragment_hit_col,\n",
    "                    compound_hit_col=compound_hit_col,\n",
    "                    fragment_score=fragment_score,\n",
    "                    compound_score=compound_score,\n",
    "                    fragment_remove_pains_brenk=fragment_remove_pains_brenk,\n",
    "                    compound_remove_pains_brenk=compound_remove_pains_brenk, \n",
    "                    fragment_require_more_than_coh=fragment_require_more_than_coh,\n",
    "                    frags_cannot_disrupt_rings=frags_cannot_disrupt_rings)\n",
    "\n",
    "# save rank_df\n",
    "rank_df = rank_df.sort_values('number_of_matched_molecules', ascending = False)\n",
    "\n",
    "# take only the largest frags\n",
    "rank_df = rank_df[rank_df['length_of_fragment'] > 7]\n",
    "rank_df = rank_df[rank_df['number_of_matched_molecules'] < 400]\n",
    "\n",
    "# get the final matching molecules for saving\n",
    "all_matching_mol_indices = [x for l in list(rank_df['matched_molecules']) for x in l]\n",
    "\n",
    "# deduplicate\n",
    "all_matching_mol_indices = list(set(all_matching_mol_indices))\n",
    "print('final number of molecules to test: ', len(all_matching_mol_indices))\n",
    "\n",
    "# save the names\n",
    "cpd_smiles = list(cpd_df['SMILES'])\n",
    "all_matching_smis = [cpd_smiles[i] for i in list(set(all_matching_mol_indices))]\n",
    "\n",
    "# and save the final molecules to df\n",
    "all_matching_mols_df = pd.DataFrame()\n",
    "all_matching_mols_df['SMILES'] = all_matching_smis\n",
    "all_matching_mols_df\n",
    "\n",
    "final_merge_df = all_matching_mols_df.merge(all_cpd_df, on = 'SMILES')\n",
    "final_merge_df = final_merge_df.sort_values('class', ascending = False)\n",
    "final_merge_df.to_csv('../out/controls/in_silico_algorithm_control_SA_final_proposed_fake_mols_to_order.csv', index = False)\n",
    "\n",
    "predicted_positive_cpds = list(final_merge_df['Compound_ID'])\n",
    "all_cpd_df['predicted_with_algo'] = [1.0 if x in predicted_positive_cpds else 0.0 for x in list(all_cpd_df['Compound_ID'])]\n",
    "print(str(sum(all_cpd_df['experimental_hit'])) + ' experimental hits out of ' + str(sum(all_cpd_df['predicted_with_algo'])) + ' predicted hits')\n",
    "evaluate_model(all_cpd_df, cutoff_for_positive = 0.2, actual_col='experimental_hit', predicted_col='predicted_with_algo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
